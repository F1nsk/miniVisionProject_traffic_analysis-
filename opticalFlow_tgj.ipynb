{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d0b79821127b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#cv2.imshow('frame',img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('intersection.mp4')\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "#Counter used to trigger new points to track\n",
    "n=0\n",
    "\n",
    "\n",
    "while(1):\n",
    "    n +=1\n",
    "    ret,frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #frame_gray = fgmask\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    if n == 100:\n",
    "        p0=cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "        n = 0\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9108048c94df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfgmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfgmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myNDArray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-15d310f2b472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyNDArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVideoTracker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Class with different functions for tracking objects in videos\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myNDArray' is not defined"
     ]
    }
   ],
   "source": [
    "myNDArray\n",
    "class VideoTracker:\n",
    "    \"\"\"Class with different functions for tracking objects in videos\"\"\"\n",
    "\n",
    "    def __init__(self, video_path):\n",
    "        self.videoPath = video_path\n",
    "        self.video = cv2.VideoCapture(video_path)\n",
    "\n",
    "        self.clicked = False\n",
    "        self.blur = 1\n",
    "        self.kernelSize = 1\n",
    "        self.it0 = 0\n",
    "        self.it1 = 0\n",
    "        self.it2 = 0\n",
    "\n",
    "    # Function that is called whenever the mouse is clicked. Remember to set callback.\n",
    "    def on_mouse(self, event, x, y, flag, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.mouseX = x\n",
    "            self.mouseY = y\n",
    "            self.clicked = True\n",
    "\n",
    "    # Click on four points in a square to make a transformation.\n",
    "    def click_to_make_transformation(self, window_name, frame_number = 0):\n",
    "        self.video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "        ret, image = self.video.read()\n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.setMouseCallback(window_name, self.on_mouse)\n",
    "        cv2.imshow(window_name, image)\n",
    "        cv2.waitKey(200)\n",
    "\n",
    "        counter = 0\n",
    "        number_of_points = 4\n",
    "        pts_src = np.empty(shape=[0, 2], dtype=np.int32)\n",
    "        while counter < number_of_points:\n",
    "            cv2.waitKey(100)\n",
    "            if self.clicked:\n",
    "                pts_src = np.append(pts_src, [[self.mouseX, self.mouseY]], axis=0)\n",
    "                self.clicked = False\n",
    "                counter += 1\n",
    "\n",
    "        edge = 100\n",
    "        shape = image.shape\n",
    "        x = shape[1]\n",
    "        y = shape[0]\n",
    "        pts_dst = np.array(\n",
    "            [[0 + edge, 0 + edge], [x - edge, 0 + edge], [x - edge, y - edge], [0 + edge, y - edge]])\n",
    "\n",
    "        self.h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "        self.size = (x, y)\n",
    "\n",
    "    def nothing(x, y):\n",
    "        pass\n",
    "\n",
    "    # Manipulate the parameters using trackbars\n",
    "    def trackbars(self, window_name):\n",
    "        cv2.namedWindow('Trackbars', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Trackbars', 600, 270)\n",
    "\n",
    "        cv2.createTrackbar('Blur', window_name, 1, 25, self.nothing)\n",
    "        cv2.createTrackbar('KernelSize', window_name, 1, 25, self.nothing)\n",
    "        cv2.createTrackbar('it0', window_name, 0, 25, self.nothing)\n",
    "        cv2.createTrackbar('it1', window_name, 0, 25, self.nothing)\n",
    "        cv2.createTrackbar('it2', window_name, 0, 25, self.nothing)\n",
    "        cv2.createTrackbar('BG_frames', window_name, 0, 100, self.nothing)\n",
    "        cv2.createTrackbar('BG_thresh', window_name, 0, 100, self.nothing)\n",
    "\n",
    "        old_background_frames = 0\n",
    "        old_background_thresh = 0\n",
    "\n",
    "        while True:\n",
    "            k = cv2.waitKey(1) & 0xFF\n",
    "            if k == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "\n",
    "            self.blur = cv2.getTrackbarPos('Blur', window_name)\n",
    "            if self.blur % 2 == 0:\n",
    "                self.blur = self.blur + 1\n",
    "\n",
    "            self.kernelSize = cv2.getTrackbarPos('KernelSize', window_name)\n",
    "            if self.kernelSize % 2 == 0:\n",
    "                self.kernelSize = self.kernelSize + 1\n",
    "\n",
    "            self.it0 = cv2.getTrackbarPos('it0', window_name)\n",
    "            self.it1 = cv2.getTrackbarPos('it1', window_name)\n",
    "            self.it2 = cv2.getTrackbarPos('it2', window_name)\n",
    "\n",
    "            background_frames = cv2.getTrackbarPos('BG_frames', window_name)\n",
    "            background_thresh = cv2.getTrackbarPos('BG_thresh', window_name)\n",
    "\n",
    "            if background_frames < 1:\n",
    "                background_frames = 1\n",
    "\n",
    "            if background_thresh < 1:\n",
    "                background_thresh = 1\n",
    "\n",
    "            frames_changed = background_frames != old_background_frames\n",
    "            tresh_changed = background_thresh != old_background_thresh\n",
    "            if frames_changed or tresh_changed:\n",
    "                self.create_background_subtractor(background_frames, background_thresh)\n",
    "\n",
    "            old_background_thresh = background_thresh\n",
    "            old_background_frames = background_frames\n",
    "\n",
    "\n",
    "    # Start thread with trackbars\n",
    "    def display_trackbars(self, window_name):\n",
    "        thread = Thread(target=self.trackbars, args=(window_name,))\n",
    "        thread.start()\n",
    "\n",
    "    def create_background_subtractor(self, frames, threshold):\n",
    "        self.backgroundSubtractor = cv2.createBackgroundSubtractorMOG2(frames, threshold, True)\n",
    "\n",
    "    def subtract_background(self, use_transformation=False):\n",
    "        ret, frame = self.video.read()\n",
    "\n",
    "        frame = cv2.blur(frame, (self.blur, self.blur))\n",
    "\n",
    "        if use_transformation:\n",
    "            frame = cv2.warpPerspective(frame, self.h, self.size)\n",
    "\n",
    "        fgmask = self.backgroundSubtractor.apply(frame)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (self.kernelSize, self.kernelSize))\n",
    "        fgmask = cv2.erode(fgmask, kernel, iterations=self.it0)\n",
    "        fgmask = cv2.dilate(fgmask, kernel, iterations=self.it1)\n",
    "        fgmask = cv2.erode(fgmask, kernel, iterations=self.it2)\n",
    "\n",
    "        fgmask = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "        return frame, fgmask\n",
    "\n",
    "    # Subtract the background.\n",
    "    def run_background_subtractor(self, window_name, use_transformation=False):\n",
    "        while True:\n",
    "            frame, background = self.subtract_background(use_transformation)\n",
    "\n",
    "            display_image = cv2.addWeighted(frame, 0.5, background, 0.5, 0.0)\n",
    "\n",
    "            cv2.imshow(window_name, display_image)\n",
    "            k = cv2.waitKey(10) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "    # Subtract the background, then detect and mark blobs.\n",
    "    def run_background_subtractor_with_blob_detection(self, window_name, use_transformation=False):\n",
    "        has_completed_one_cycle = False\n",
    "        while True:\n",
    "            frame, background = self.subtract_background(use_transformation)\n",
    "\n",
    "            background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            if has_completed_one_cycle:\n",
    "                self.blob_detection(window_name, background, frame, 4)\n",
    "\n",
    "            k = cv2.waitKey(10) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "            has_completed_one_cycle = True\n",
    "\n",
    "    # Use blob detection on an image and display the found blobs on another image.\n",
    "    def blob_detection(self, window_name, detect_image, display_image, connectivity=4):\n",
    "        ret, thresh = cv2.threshold(detect_image, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Perform the operation\n",
    "        output = cv2.connectedComponentsWithStats(thresh, connectivity, cv2.CV_32S)\n",
    "\n",
    "        # Get the results\n",
    "        # The first cell is the number of labels\n",
    "        num_labels = output[0]\n",
    "        # The second cell is the label matrix\n",
    "        labels = output[1]\n",
    "        # The third cell is the stat matrix\n",
    "        stats = output[2]\n",
    "        # The fourth cell is the centroid matrix\n",
    "        centroids = output[3]\n",
    "\n",
    "        # Draw circles where blobs where found\n",
    "        for i, val in enumerate(centroids):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            cv2.circle(display_image, (int(centroids[i][0]), int(centroids[i][1])), 10, (255, 0, 0), 3, 8, 0)\n",
    "\n",
    "        # Show the result\n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(window_name, display_image)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        new_window_name = window_name + \": \" + str(num_labels)\n",
    "        cv2.setWindowTitle(window_name, new_window_name)\n",
    "        global myNDArray \n",
    "        myNDArray= centroids\n",
    "\n",
    "    # Display both background subtraction and blobs detected\n",
    "    def run_background_and_blobs(self, window_name_background, window_name_blobs, use_transformation=False):\n",
    "        has_completed_one_cycle = False\n",
    "        while True:\n",
    "            frame, background = self.subtract_background(use_transformation)\n",
    "\n",
    "            display_image = cv2.addWeighted(frame, 0.5, background, 0.5, 0.0)\n",
    "\n",
    "            cv2.imshow(window_name_background, display_image)\n",
    "\n",
    "            background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            if has_completed_one_cycle:\n",
    "                self.blob_detection(window_name_blobs, background, frame, 8)\n",
    "\n",
    "            k = cv2.waitKey(1) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "            has_completed_one_cycle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('intersection.mp4')\n",
    "# params for ShiTomasi corner detection\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "color =(150,100,3)\n",
    "mask = np.zeros_like(old_frame)\n",
    "cap.release()\n",
    "_number_of_frames = 0\n",
    "\n",
    "def opticalFlowTracking(pointArray2Track):\n",
    "    p0 = pointArray2Track\n",
    "    ret,frame=cap.read()\n",
    "    frame_grey =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray,frame_grey,p0,None, **lk_params)\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    # Drawing the points\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow(img,\"frame\")\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VideoTracker import VideoTracker\n",
    "from threading import Thread\n",
    "vt = VideoTracker('intersection.mp4')\n",
    "\n",
    "\n",
    "\n",
    "vt.create_background_subtractor(50, 16)\n",
    "vt.click_to_make_transformation('Display', 0)\n",
    "#vt.display_trackbars('Trackbars')\n",
    "\n",
    "#vt.run_background_and_blobs('Display', 'Blobs', True)\n",
    "\n",
    "#opticalFlowTracking(myNDArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
